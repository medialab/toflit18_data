library(sp)
library(sf)
library(rgdal)
library(gstat)
library(automap)
library(raster)
library(stringr)
library(spatialEco)
library(exactextractr)
library(ncdf4)
library(tidyverse)
library(ncdump)
library(sf)
library(lattice)
library(RColorBrewer)
library(parallel)
library(chirps)
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library(rdhs)
### Chargement de la carte du Snégal
Senegal <- ne_states(country = "Senegal", returnclass = "sp")
install.packages("rnaturalearthhires", repos = "http://packages.ropensci.org", type = "source")
library(sp)
library(sf)
library(rgdal)
library(gstat)
library(automap)
library(raster)
library(stringr)
library(spatialEco)
library(exactextractr)
library(ncdf4)
library(tidyverse)
library(ncdump)
library(sf)
library(lattice)
library(RColorBrewer)
library(parallel)
library(chirps)
library("ggplot2")
theme_set(theme_bw())
library("sf")
library("rnaturalearth")
library("rnaturalearthdata")
library("rnaturalearthhires")
library(rdhs)
rm(list = ls())
### On se connecte à ma session DHS
set_rdhs_config(email = "edouard.pignede@ird.fr",
project = "Senegal vulnerability to climate change")
### On selectionne le DHS chargé que l'on veut télécharger
### SN => Sénégal ; FL => Flat file :plus rapide ;HR => Household Recode ; KR => children's recode
datasets_HR <- dhs_datasets(countryIds = "SN",
surveyYear = "2019",
fileFormat = "FL",
fileType = "HR" )
datasets_KR <- dhs_datasets(countryIds = "SN",
surveyYear = "2019",
fileFormat = "FL",
fileType = "KR" )
datasets_IR <- dhs_datasets(countryIds = "SN",
surveyYear = "2019",
fileFormat = "FL",
fileType = "IR" )
### On le télécharge
downloads_HR <- get_datasets(datasets_HR$FileName)
downloads_KR <- get_datasets(datasets_KR$FileName)
downloads_IR <- get_datasets(datasets_IR$FileName)
### On le charge sur R
data_hous <- readRDS(downloads_HR$SNHR8AFL)
data_child <- readRDS(downloads_KR$SNKR8AFL)
data_women <- readRDS(downloads_IR$SNIR8AFL)
data_women$v106
library(dplyr)
library(plyr)
library(tidyverse)
library(stringr)
library(readr)
library(pracma)
library(IndexNumR)
library(hpiR)
library(tidyverse)
read_sav("C:/Users/pignede/menage_final.sav")
install.packages("haven")
read_sav("C:/Users/pignede/menage_final.sav")
devtools::install_github("tidyverse/haven")
devtools::install_github("tidyverse/haven")
library(haven)
install.packages("haven")
library(haven)
read_sav("C:/Users/pignede/menage_final.sav")
read_sav("C:/Users/pignede/Telechargements/menage_final.sav")
read_sav("C:/Users/pignede/Downloads/menage_final.sav")
as.data.frame(read_sav("C:/Users/pignede/Downloads/menage_final.sav"))
a <- read_sav("C:/Users/pignede/Downloads/menage_final.sav")
a$id_menage
a$region
a$departement
a$M10
a$M9
library(sp)
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
library(dplyr)
library(tidyverse)
library(stringr)
library(readr)
library(pracma)
library(openxlsx)
library(hpiR)
### Nettoyage de l'espace de travail
rm(list = ls())
### A définir: emplacement du working directory
setwd("C:/Users/pignede/Documents/GitHub/toflit18_data")
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
### On récupère l'ensemble des villes du csv des indices
liste_ville <- unique(Index_res[ , 1])
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = dim(liste_ville)[1], ncol = dim(liste_ville)[1],
dimnames = list(liste_ville, liste_ville))
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = dim(liste_ville), ncol = dim(liste_ville),
dimnames = list(liste_ville, liste_ville))
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = length(liste_ville), ncol = length(liste_ville),
dimnames = list(liste_ville, liste_ville))
### On importe la base de données courante
bdd_courante <- read.csv(unz("./base/bdd courante.csv.zip", "bdd courante.csv") , encoding = "UTF-8")
Value_com_tot <- bdd_courante %>%
filter(best_guess_region_prodxpart == 1) %>%
filter(customs_region == "Bayonne")
View(Value_com_tot)
i = 1
j= 2
Index1 <- Indes_res_baseline %>%
filter(Ville == liste_ville[i], Type == "Imports") %>%
select(c("year", "Index_value"))
### On conserve uniquement la baseline
Index_res_baseline <- Index_res %>%
filter(Outliers == T & Outliers_coef == 10 & Trans_number == 0 & Prod_problems == F &
Product_select == F & Remove_double == T & Ponderation == T & Pond_log == F)
Index1 <- Indes_res_baseline %>%
filter(Ville == liste_ville[i], Type == "Imports") %>%
select(c("year", "Index_value"))
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Type == "Imports") %>%
select(c("year", "Index_value"))
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == "Imports") %>%
select(c("year", "Index_value"))
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == "Imports") %>%
select(c("year", "Index_value"))
cor <- cor(Index1, Index2, use = "complete.obs")
Index1
Index2
cor <- cor(Index1, Index2, use = "pairwise.complete.obs")
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == "Imports") %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == "Imports") %>%
select(c("year", "Index_value")) %>%
drop_na()
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == "Imports") %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == "Imports") %>%
select(c("year", "Index_value")) %>%
drop_na() %>%
filter(year %in% Index1$year)
Index1 <- Index1 %>% filter(year %in% Index2$year)
Index1
Index2
cor <- cor(Index1, Index2, use = "complete.obs")
cor
Calcul_correlation_matrix_ville <- function()
{
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
### Création d'un workbook (objet comparable à un excel et converti en excel à la fin)
Cor_matrix_workbook <- createWorkbook()
for (Type in c("Imports", "Exports")) {
### On récupère l'ensemble des villes du csv des indices
liste_ville <- unique(Index_res[ , 1])
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = length(liste_ville), ncol = length(liste_ville),
dimnames = list(liste_ville, liste_ville))
### On conserve uniquement la baseline
Index_res_baseline <- Index_res %>%
filter(Outliers == T & Outliers_coef == 10 & Trans_number == 0 & Prod_problems == F &
Product_select == F & Remove_double == T & Ponderation == T & Pond_log == F)
for (i in length(liste_ville)) {
for (j in length(liste_ville)) {
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na() %>%
filter(year %in% Index1$year)
Index1 <- Index1 %>% filter(year %in% Index2$year)
cor <- cor(Index1, Index2, use = "complete.obs")
if (cor[1,1] > 0.99) {
Correlation_matrix[i, j] = cor[2,2]
} else {
Correlation_matrix[i, j] = NA
}
}
}
### On crée un nouvel onglet ville type au workbook
addWorksheet(Cor_matrix_workbook, sheetName = paste(Type))
### On ajoute la matrice de corrélation dans l'onglet ville type
writeData(Cor_matrix_workbook,
sheet = paste(Type),
x = Correlation_matrix,
rowNames = T,
colNames = T)
}
### On sauvegarde le workbook dans l'excel Correlation_matrix.xlsx
saveWorkbook(Cor_matrix_workbook, "./scripts/Edouard/Correlation_matrix.xlsx",
overwrite = T)
}
Calcul_correlation_matrix_ville <- function()
{
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
### Création d'un workbook (objet comparable à un excel et converti en excel à la fin)
Cor_matrix_workbook <- createWorkbook()
for (Type in c("Imports", "Exports")) {
### On récupère l'ensemble des villes du csv des indices
liste_ville <- unique(Index_res[ , 1])
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = length(liste_ville), ncol = length(liste_ville),
dimnames = list(liste_ville, liste_ville))
### On conserve uniquement la baseline
Index_res_baseline <- Index_res %>%
filter(Outliers == T & Outliers_coef == 10 & Trans_number == 0 & Prod_problems == F &
Product_select == F & Remove_double == T & Ponderation == T & Pond_log == F)
for (i in length(liste_ville)) {
for (j in length(liste_ville)) {
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na() %>%
filter(year %in% Index1$year)
Index1 <- Index1 %>% filter(year %in% Index2$year)
cor <- cor(Index1, Index2, use = "complete.obs")
if (cor[1,1] > 0.99) {
Correlation_matrix[i, j] = cor[2,2]
} else {
Correlation_matrix[i, j] = NA
}
}
}
### On crée un nouvel onglet ville type au workbook
addWorksheet(Cor_matrix_workbook, sheetName = paste(Type))
### On ajoute la matrice de corrélation dans l'onglet ville type
writeData(Cor_matrix_workbook,
sheet = paste(Type),
x = Correlation_matrix,
rowNames = T,
colNames = T)
}
### On sauvegarde le workbook dans l'excel Correlation_matrix.xlsx
saveWorkbook(Cor_matrix_workbook, "./scripts/Edouard/Correlation_matrix_ville.xlsx",
overwrite = T)
}
Calcul_correlation_matrix_ville()
Calcul_correlation_matrix_ville <- function()
{
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
### On conserve uniquement la baseline
Index_res_baseline <- Index_res %>%
filter(Outliers == T & Outliers_coef == 10 & Trans_number == 0 & Prod_problems == F &
Product_select == F & Remove_double == T & Ponderation == T & Pond_log == F)
### Création d'un workbook (objet comparable à un excel et converti en excel à la fin)
Cor_matrix_workbook <- createWorkbook()
### On récupère l'ensemble des villes du csv des indices
liste_ville <- unique(Index_res[ , 1])
for (Type in c("Imports", "Exports")) {
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = length(liste_ville), ncol = length(liste_ville),
dimnames = list(liste_ville, liste_ville))
for (i in length(liste_ville)) {
for (j in length(liste_ville)) {
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na() %>%
filter(year %in% Index1$year)
Index1 <- Index1 %>% filter(year %in% Index2$year)
cor <- cor(Index1, Index2, use = "complete.obs")
if (cor[1,1] > 0.99) {
Correlation_matrix[i, j] = cor[2,2]
} else {
Correlation_matrix[i, j] = NA
}
}
}
### On crée un nouvel onglet ville type au workbook
addWorksheet(Cor_matrix_workbook, sheetName = paste(Type))
### On ajoute la matrice de corrélation dans l'onglet ville type
writeData(Cor_matrix_workbook,
sheet = paste(Type),
x = Correlation_matrix,
rowNames = T,
colNames = T)
}
### On sauvegarde le workbook dans l'excel Correlation_matrix.xlsx
saveWorkbook(Cor_matrix_workbook, "./scripts/Edouard/Correlation_matrix_ville.xlsx",
overwrite = T)
}
Calcul_correlation_matrix_ville()
Calcul_correlation_matrix_ville()
length(liste_ville)
Calcul_correlation_matrix_ville <- function()
{
### On charge les valeurs de Index_results.csv
Index_res <- read.csv2("./scripts/Edouard/Index_results.csv", row.names = NULL, dec = ",")
### On conserve uniquement la baseline
Index_res_baseline <- Index_res %>%
filter(Outliers == T & Outliers_coef == 10 & Trans_number == 0 & Prod_problems == F &
Product_select == F & Remove_double == T & Ponderation == T & Pond_log == F)
### Création d'un workbook (objet comparable à un excel et converti en excel à la fin)
Cor_matrix_workbook <- createWorkbook()
### On récupère l'ensemble des villes du csv des indices
liste_ville <- unique(Index_res[ , 1])
for (Type in c("Imports", "Exports")) {
### Création de la matrice de corrélation les noms des lignes et des colonnes sont égales à col_names
Correlation_matrix <- matrix(nrow = length(liste_ville), ncol = length(liste_ville),
dimnames = list(liste_ville, liste_ville))
for (i in seq(1,length(liste_ville))) {
for (j in seq(1,length(liste_ville))) {
Index1 <- Index_res_baseline %>%
filter(Ville == liste_ville[i], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na()
Index2 <- Index_res_baseline %>%
filter(Ville == liste_ville[j], Exports_imports == Type) %>%
select(c("year", "Index_value")) %>%
drop_na() %>%
filter(year %in% Index1$year)
Index1 <- Index1 %>% filter(year %in% Index2$year)
cor <- cor(Index1, Index2, use = "complete.obs")
if (cor[1,1] > 0.99) {
Correlation_matrix[i, j] = cor[2,2]
} else {
Correlation_matrix[i, j] = NA
}
}
}
### On crée un nouvel onglet ville type au workbook
addWorksheet(Cor_matrix_workbook, sheetName = paste(Type))
### On ajoute la matrice de corrélation dans l'onglet ville type
writeData(Cor_matrix_workbook,
sheet = paste(Type),
x = Correlation_matrix,
rowNames = T,
colNames = T)
}
### On sauvegarde le workbook dans l'excel Correlation_matrix.xlsx
saveWorkbook(Cor_matrix_workbook, "./scripts/Edouard/Correlation_matrix_ville.xlsx",
overwrite = T)
}
length(liste_ville)
Calcul_correlation_matrix_ville()
